{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rKzTjWHiVwY6"
      },
      "outputs": [],
      "source": [
        "faqs = \"\"\"About the Program\n",
        "What is the course fee for  Data Science Mentorship Program (DSMP 2023)\n",
        "The course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\n",
        "What is the total duration of the course?\n",
        "The total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\n",
        "What is the syllabus of the mentorship program?\n",
        "We will be covering the following modules:\n",
        "Python Fundamentals\n",
        "Python libraries for Data Science\n",
        "Data Analysis\n",
        "SQL for Data Science\n",
        "Maths for Machine Learning\n",
        "ML Algorithms\n",
        "Practical ML\n",
        "MLOPs\n",
        "Case studies\n",
        "You can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\n",
        "Will Deep Learning and NLP be a part of this program?\n",
        "No, NLP and Deep Learning both are not a part of this program’s curriculum.\n",
        "What if I miss a live session? Will I get a recording of the session?\n",
        "Yes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\n",
        "Where can I find the class schedule?\n",
        "Checkout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\n",
        "What is the time duration of all the live sessions?\n",
        "Roughly, all the sessions last 2 hours.\n",
        "What is the language spoken by the instructor during the sessions?\n",
        "Hinglish\n",
        "How will I be informed about the upcoming class?\n",
        "You will get a mail from our side before every paid session once you become a paid user.\n",
        "Can I do this course if I am from a non-tech background?\n",
        "Yes, absolutely.\n",
        "I am late, can I join the program in the middle?\n",
        "Absolutely, you can join the program anytime.\n",
        "If I join/pay in the middle, will I be able to see all the past lectures?\n",
        "Yes, once you make the payment you will be able to see all the past content in your dashboard.\n",
        "Where do I have to submit the task?\n",
        "You don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\n",
        "Will we do case studies in the program?\n",
        "Yes.\n",
        "Where can we contact you?\n",
        "You can mail us at nitish.campusx@gmail.com\n",
        "Payment/Registration related questions\n",
        "Where do we have to make our payments? Your YouTube channel or website?\n",
        "You have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\n",
        "Can we pay the entire amount of Rs 5600 all at once?\n",
        "Unfortunately no, the program follows a monthly subscription model.\n",
        "What is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n",
        "15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\n",
        "What if I don’t like the course after making the payment. What is the refund policy?\n",
        "You get a 7 days refund period from the day you have made the payment.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmail.com\n",
        "Post registration queries\n",
        "Till when can I view the paid videos on the website?\n",
        "This one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\n",
        "But once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\n",
        "Why lifetime validity is not provided?\n",
        "Because of the low course fee.\n",
        "Where can I reach out in case of a doubt after the session?\n",
        "You will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\n",
        "If I join the program late, can I still ask past week doubts?\n",
        "Yes, just select past week doubt in the doubt clearance google form.\n",
        "I am living outside India and I am not able to make the payment on the website, what should I do?\n",
        "You have to contact us by sending a mail at nitish.campusx@gmai.com\n",
        "Certificate and Placement Assistance related queries\n",
        "What is the criteria to get the certificate?\n",
        "There are 2 criterias:\n",
        "You have to pay the entire fee of Rs 5600\n",
        "You have to attempt all the course assessments.\n",
        "I am joining late. How can I pay payment of the earlier months?\n",
        "You will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\n",
        "I have read that Placement assistance is a part of this program. What comes under Placement assistance?\n",
        "This is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\n",
        "Portfolio Building sessions\n",
        "Soft skill sessions\n",
        "Sessions with industry mentors\n",
        "Discussion on Job hunting strategies\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "DrCJ1kpoV_Y-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()"
      ],
      "metadata": {
        "id": "hsq1Uya7WMMR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts([faqs])"
      ],
      "metadata": {
        "id": "WAar8QttWQ-W"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMO7Ir12WyJu",
        "outputId": "6e32f948-5abf-4716-b3a3-ec46182ef906"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "282"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXwor4s9W24o",
        "outputId": "3f00fd1a-034d-4bf0-aeab-33d995a8f859"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'the': 1, 'you': 2, 'i': 3, 'to': 4, 'a': 5, 'of': 6, 'is': 7, 'have': 8, 'will': 9, 'can': 10, 'what': 11, 'course': 12, 'program': 13, 'in': 14, 'for': 15, 'all': 16, 'sessions': 17, 'on': 18, 'be': 19, 'and': 20, 'this': 21, 'if': 22, 'am': 23, 'pay': 24, 'payment': 25, 'make': 26, 'we': 27, 'do': 28, 'subscription': 29, 'where': 30, 'rs': 31, 'so': 32, 'campusx': 33, 'session': 34, 'our': 35, 'paid': 36, 'join': 37, 'able': 38, 'your': 39, 'website': 40, 'placement': 41, 'fee': 42, 'data': 43, 'monthly': 44, 'month': 45, 'not': 46, 'get': 47, 'yes': 48, 'once': 49, 'past': 50, 'feb': 51, 'assistance': 52, 'science': 53, '7': 54, '5600': 55, 'are': 56, 'watch': 57, 'google': 58, 'by': 59, 'com': 60, 'mail': 61, 'from': 62, 'contact': 63, 'us': 64, 'at': 65, 'or': 66, 'doubt': 67, 'mentorship': 68, 'payments': 69, '799': 70, 'total': 71, 'duration': 72, 'months': 73, 'learning': 74, 'case': 75, 'here': 76, 'https': 77, 'part': 78, 'see': 79, 'late': 80, 'dashboard': 81, 'task': 82, 'don’t': 83, 'nitish': 84, 'validity': 85, '15th': 86, 'jan': 87, 'period': 88, 'after': 89, 'till': 90, '21st': 91, 'that': 92, 'about': 93, 'follows': 94, 'model': 95, 'syllabus': 96, 'python': 97, 'ml': 98, 'studies': 99, 'learnwith': 100, 'deep': 101, 'nlp': 102, 'no': 103, 'miss': 104, 'live': 105, 'recording': 106, 'even': 107, 'class': 108, 'time': 109, '2': 110, 'how': 111, 'absolutely': 112, 'middle': 113, 'anytime': 114, 'submit': 115, 'with': 116, 'gmail': 117, 'registration': 118, 'related': 119, 'link': 120, 'entire': 121, 'suppose': 122, 'again': 123, 'days': 124, 'day': 125, 'refund': 126, 'living': 127, 'outside': 128, 'india': 129, 'should': 130, 'sending': 131, 'queries': 132, 'videos': 133, 'read': 134, 'but': 135, 'provided': 136, 'form': 137, '1': 138, 'clearance': 139, 'week': 140, 'just': 141, 'certificate': 142, 'earlier': 143, 'comes': 144, 'under': 145, 'guarantee': 146, 'dsmp': 147, '2023': 148, 'becomes': 149, 'approx': 150, 'covering': 151, 'following': 152, 'modules': 153, 'fundamentals': 154, 'libraries': 155, 'analysis': 156, 'sql': 157, 'maths': 158, 'machine': 159, 'algorithms': 160, 'practical': 161, 'mlops': 162, 'check': 163, 'detailed': 164, 'courses': 165, '637339afe4b0615a1bbed390': 166, 'both': 167, 'program’s': 168, 'curriculum': 169, 'recorded': 170, 'go': 171, 'back': 172, 'find': 173, 'schedule': 174, 'checkout': 175, 'sheet': 176, 'table': 177, 'docs': 178, 'spreadsheets': 179, 'd': 180, '16ootax': 181, 'a6oraecg4emgexhqqpv3noqpyku7rj6arozk': 182, 'edit': 183, 'usp': 184, 'sharing': 185, 'roughly': 186, 'last': 187, 'hours': 188, 'language': 189, 'spoken': 190, 'instructor': 191, 'during': 192, 'hinglish': 193, 'informed': 194, 'upcoming': 195, 'side': 196, 'before': 197, 'every': 198, 'become': 199, 'user': 200, 'non': 201, 'tech': 202, 'background': 203, 'lectures': 204, 'content': 205, 'provide': 206, 'solutions': 207, 'self': 208, 'evaluate': 209, 'yourself': 210, 'questions': 211, 'youtube': 212, 'channel': 213, 'amount': 214, 'unfortunately': 215, 'then': 216, '1st': 217, '30': 218, 'essentially': 219, 'wait': 220, 'end': 221, 'like': 222, 'making': 223, 'policy': 224, 'made': 225, 'post': 226, 'when': 227, 'view': 228, 'one': 229, 'tricky': 230, 'carefully': 231, 'valid': 232, 'purchased': 233, '20th': 234, 'purchase': 235, 'over': 236, 'installments': 237, 'aug': 238, '2024': 239, 'why': 240, 'lifetime': 241, 'because': 242, 'low': 243, 'reach': 244, 'out': 245, 'fill': 246, 'team': 247, 'still': 248, 'ask': 249, 'doubts': 250, 'select': 251, 'gmai': 252, 'criteria': 253, 'there': 254, 'criterias': 255, 'attempt': 256, 'assessments': 257, 'joining': 258, 'current': 259, 'clarify': 260, 'does': 261, 'mean': 262, 'dont': 263, 'any': 264, 'jobs': 265, 'matter': 266, 'interview': 267, 'calls': 268, 'planning': 269, 'placements': 270, 'afraid': 271, 'disappointed': 272, 'portfolio': 273, 'building': 274, 'soft': 275, 'skill': 276, 'industry': 277, 'mentors': 278, 'discussion': 279, 'job': 280, 'hunting': 281, 'strategies': 282}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.word_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ws_kGHrAYowN",
        "outputId": "ed2e01fc-5749-458a-faa7-a9d5e34b6bcc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict({'about': 2, 'the': 69, 'program': 11, 'what': 14, 'is': 18, 'course': 12, 'fee': 5, 'for': 10, 'data': 5, 'science': 4, 'mentorship': 3, 'dsmp': 1, '2023': 1, 'follows': 2, 'a': 19, 'monthly': 5, 'subscription': 6, 'model': 2, 'where': 6, 'you': 37, 'have': 18, 'to': 27, 'make': 7, 'payments': 3, 'of': 19, 'rs': 6, '799': 3, 'month': 5, 'total': 3, 'duration': 3, '7': 4, 'months': 3, 'so': 6, 'becomes': 1, '5600': 4, 'approx': 1, 'syllabus': 2, 'we': 7, 'will': 16, 'be': 8, 'covering': 1, 'following': 1, 'modules': 1, 'python': 2, 'fundamentals': 1, 'libraries': 1, 'analysis': 1, 'sql': 1, 'maths': 1, 'machine': 1, 'learning': 3, 'ml': 2, 'algorithms': 1, 'practical': 1, 'mlops': 1, 'case': 3, 'studies': 2, 'can': 15, 'check': 1, 'detailed': 1, 'here': 3, 'https': 3, 'learnwith': 2, 'campusx': 6, 'in': 11, 'courses': 1, '637339afe4b0615a1bbed390': 1, 'deep': 2, 'and': 8, 'nlp': 2, 'part': 3, 'this': 8, 'no': 2, 'both': 1, 'are': 4, 'not': 5, 'program’s': 1, 'curriculum': 1, 'if': 8, 'i': 28, 'miss': 2, 'live': 2, 'session': 6, 'get': 5, 'recording': 2, 'yes': 5, 'all': 9, 'our': 6, 'sessions': 9, 'recorded': 1, 'even': 2, 'go': 1, 'back': 1, 'watch': 4, 'find': 1, 'class': 2, 'schedule': 1, 'checkout': 1, 'google': 4, 'sheet': 1, 'see': 3, 'by': 4, 'time': 2, 'table': 1, 'docs': 1, 'com': 4, 'spreadsheets': 1, 'd': 1, '16ootax': 1, 'a6oraecg4emgexhqqpv3noqpyku7rj6arozk': 1, 'edit': 1, 'usp': 1, 'sharing': 1, 'roughly': 1, 'last': 1, '2': 2, 'hours': 1, 'language': 1, 'spoken': 1, 'instructor': 1, 'during': 1, 'hinglish': 1, 'how': 2, 'informed': 1, 'upcoming': 1, 'mail': 4, 'from': 4, 'side': 1, 'before': 1, 'every': 1, 'paid': 6, 'once': 5, 'become': 1, 'user': 1, 'do': 7, 'am': 8, 'non': 1, 'tech': 1, 'background': 1, 'absolutely': 2, 'late': 3, 'join': 6, 'middle': 2, 'anytime': 2, 'pay': 8, 'able': 6, 'past': 5, 'lectures': 1, 'payment': 8, 'content': 1, 'your': 6, 'dashboard': 3, 'submit': 2, 'task': 3, 'don’t': 3, 'provide': 1, 'with': 2, 'solutions': 1, 'self': 1, 'evaluate': 1, 'yourself': 1, 'contact': 4, 'us': 4, 'at': 4, 'nitish': 3, 'gmail': 2, 'registration': 2, 'related': 2, 'questions': 1, 'youtube': 1, 'channel': 1, 'or': 4, 'website': 6, 'on': 9, 'link': 2, 'entire': 2, 'amount': 1, 'unfortunately': 1, 'validity': 3, 'suppose': 2, '15th': 3, 'jan': 3, 'then': 1, 'again': 2, '1st': 1, 'feb': 5, 'period': 3, '30': 1, 'days': 2, 'day': 2, 'essentially': 1, 'wait': 1, 'end': 1, 'like': 1, 'after': 3, 'making': 1, 'refund': 2, 'policy': 1, 'made': 1, 'living': 2, 'outside': 2, 'india': 2, 'should': 2, 'sending': 2, 'post': 1, 'queries': 2, 'till': 3, 'when': 1, 'view': 1, 'videos': 2, 'one': 1, 'tricky': 1, 'read': 2, 'carefully': 1, 'valid': 1, 'purchased': 1, '21st': 3, '20th': 1, 'but': 2, 'purchase': 1, 'over': 1, 'installments': 1, 'aug': 1, '2024': 1, 'why': 1, 'lifetime': 1, 'provided': 2, 'because': 1, 'low': 1, 'reach': 1, 'out': 1, 'doubt': 4, 'fill': 1, 'form': 2, 'team': 1, '1': 2, 'clearance': 2, 'still': 1, 'ask': 1, 'week': 2, 'doubts': 1, 'just': 2, 'select': 1, 'gmai': 1, 'certificate': 2, 'placement': 6, 'assistance': 5, 'criteria': 1, 'there': 1, 'criterias': 1, 'attempt': 1, 'assessments': 1, 'joining': 1, 'earlier': 2, 'current': 1, 'that': 3, 'comes': 2, 'under': 2, 'clarify': 1, 'does': 1, 'mean': 1, 'guarantee': 2, 'dont': 1, 'any': 1, 'jobs': 1, 'matter': 1, 'interview': 1, 'calls': 1, 'planning': 1, 'placements': 1, 'afraid': 1, 'disappointed': 1, 'portfolio': 1, 'building': 1, 'soft': 1, 'skill': 1, 'industry': 1, 'mentors': 1, 'discussion': 1, 'job': 1, 'hunting': 1, 'strategies': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for sentence in faqs.split('\\n'):\n",
        "  tokenized_sentence = tokenizer.texts_to_sequences([sentence])[0]\n",
        "\n",
        "  for i in range(1, len(tokenized_sentence)):\n",
        "    input_sequences.append(tokenized_sentence[:i+1])"
      ],
      "metadata": {
        "id": "ZgnR1b_BZx1b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnNkODyvey9r",
        "outputId": "f58500d4-d31b-4a8c-bfab-a6b527321045"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[93, 1], [93, 1, 13], [11, 7], [11, 7, 1], [11, 7, 1, 12], [11, 7, 1, 12, 42], [11, 7, 1, 12, 42, 15], [11, 7, 1, 12, 42, 15, 43], [11, 7, 1, 12, 42, 15, 43, 53], [11, 7, 1, 12, 42, 15, 43, 53, 68], [11, 7, 1, 12, 42, 15, 43, 53, 68, 13], [11, 7, 1, 12, 42, 15, 43, 53, 68, 13, 147], [11, 7, 1, 12, 42, 15, 43, 53, 68, 13, 147, 148], [1, 12], [1, 12, 94], [1, 12, 94, 5], [1, 12, 94, 5, 44], [1, 12, 94, 5, 44, 29], [1, 12, 94, 5, 44, 29, 95], [1, 12, 94, 5, 44, 29, 95, 30], [1, 12, 94, 5, 44, 29, 95, 30, 2], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31, 70], [1, 12, 94, 5, 44, 29, 95, 30, 2, 8, 4, 26, 44, 69, 6, 31, 70, 45], [11, 7], [11, 7, 1], [11, 7, 1, 71], [11, 7, 1, 71, 72], [11, 7, 1, 71, 72, 6], [11, 7, 1, 71, 72, 6, 1], [11, 7, 1, 71, 72, 6, 1, 12], [1, 71], [1, 71, 72], [1, 71, 72, 6], [1, 71, 72, 6, 1], [1, 71, 72, 6, 1, 12], [1, 71, 72, 6, 1, 12, 7], [1, 71, 72, 6, 1, 12, 7, 54], [1, 71, 72, 6, 1, 12, 7, 54, 73], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31, 55], [1, 71, 72, 6, 1, 12, 7, 54, 73, 32, 1, 71, 12, 42, 149, 70, 54, 31, 55, 150], [11, 7], [11, 7, 1], [11, 7, 1, 96], [11, 7, 1, 96, 6], [11, 7, 1, 96, 6, 1], [11, 7, 1, 96, 6, 1, 68], [11, 7, 1, 96, 6, 1, 68, 13], [27, 9], [27, 9, 19], [27, 9, 19, 151], [27, 9, 19, 151, 1], [27, 9, 19, 151, 1, 152], [27, 9, 19, 151, 1, 152, 153], [97, 154], [97, 155], [97, 155, 15], [97, 155, 15, 43], [97, 155, 15, 43, 53], [43, 156], [157, 15], [157, 15, 43], [157, 15, 43, 53], [158, 15], [158, 15, 159], [158, 15, 159, 74], [98, 160], [161, 98], [75, 99], [2, 10], [2, 10, 163], [2, 10, 163, 1], [2, 10, 163, 1, 164], [2, 10, 163, 1, 164, 96], [2, 10, 163, 1, 164, 96, 76], [2, 10, 163, 1, 164, 96, 76, 77], [2, 10, 163, 1, 164, 96, 76, 77, 100], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68, 13], [2, 10, 163, 1, 164, 96, 76, 77, 100, 33, 14, 165, 33, 43, 53, 68, 13, 166], [9, 101], [9, 101, 74], [9, 101, 74, 20], [9, 101, 74, 20, 102], [9, 101, 74, 20, 102, 19], [9, 101, 74, 20, 102, 19, 5], [9, 101, 74, 20, 102, 19, 5, 78], [9, 101, 74, 20, 102, 19, 5, 78, 6], [9, 101, 74, 20, 102, 19, 5, 78, 6, 21], [9, 101, 74, 20, 102, 19, 5, 78, 6, 21, 13], [103, 102], [103, 102, 20], [103, 102, 20, 101], [103, 102, 20, 101, 74], [103, 102, 20, 101, 74, 167], [103, 102, 20, 101, 74, 167, 56], [103, 102, 20, 101, 74, 167, 56, 46], [103, 102, 20, 101, 74, 167, 56, 46, 5], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21, 168], [103, 102, 20, 101, 74, 167, 56, 46, 5, 78, 6, 21, 168, 169], [11, 22], [11, 22, 3], [11, 22, 3, 104], [11, 22, 3, 104, 5], [11, 22, 3, 104, 5, 105], [11, 22, 3, 104, 5, 105, 34], [11, 22, 3, 104, 5, 105, 34, 9], [11, 22, 3, 104, 5, 105, 34, 9, 3], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6, 1], [11, 22, 3, 104, 5, 105, 34, 9, 3, 47, 5, 106, 6, 1, 34], [48, 16], [48, 16, 35], [48, 16, 35, 17], [48, 16, 35, 17, 56], [48, 16, 35, 17, 56, 170], [48, 16, 35, 17, 56, 170, 32], [48, 16, 35, 17, 56, 170, 32, 107], [48, 16, 35, 17, 56, 170, 32, 107, 22], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57, 1], [48, 16, 35, 17, 56, 170, 32, 107, 22, 2, 104, 5, 34, 2, 10, 171, 172, 20, 57, 1, 106], [30, 10], [30, 10, 3], [30, 10, 3, 173], [30, 10, 3, 173, 1], [30, 10, 3, 173, 1, 108], [30, 10, 3, 173, 1, 108, 174], [175, 21], [175, 21, 58], [175, 21, 58, 176], [175, 21, 58, 176, 4], [175, 21, 58, 176, 4, 79], [175, 21, 58, 176, 4, 79, 45], [175, 21, 58, 176, 4, 79, 45, 59], [175, 21, 58, 176, 4, 79, 45, 59, 45], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183, 184], [175, 21, 58, 176, 4, 79, 45, 59, 45, 109, 177, 6, 1, 12, 77, 178, 58, 60, 179, 180, 181, 182, 183, 184, 185], [11, 7], [11, 7, 1], [11, 7, 1, 109], [11, 7, 1, 109, 72], [11, 7, 1, 109, 72, 6], [11, 7, 1, 109, 72, 6, 16], [11, 7, 1, 109, 72, 6, 16, 1], [11, 7, 1, 109, 72, 6, 16, 1, 105], [11, 7, 1, 109, 72, 6, 16, 1, 105, 17], [186, 16], [186, 16, 1], [186, 16, 1, 17], [186, 16, 1, 17, 187], [186, 16, 1, 17, 187, 110], [186, 16, 1, 17, 187, 110, 188], [11, 7], [11, 7, 1], [11, 7, 1, 189], [11, 7, 1, 189, 190], [11, 7, 1, 189, 190, 59], [11, 7, 1, 189, 190, 59, 1], [11, 7, 1, 189, 190, 59, 1, 191], [11, 7, 1, 189, 190, 59, 1, 191, 192], [11, 7, 1, 189, 190, 59, 1, 191, 192, 1], [11, 7, 1, 189, 190, 59, 1, 191, 192, 1, 17], [111, 9], [111, 9, 3], [111, 9, 3, 19], [111, 9, 3, 19, 194], [111, 9, 3, 19, 194, 93], [111, 9, 3, 19, 194, 93, 1], [111, 9, 3, 19, 194, 93, 1, 195], [111, 9, 3, 19, 194, 93, 1, 195, 108], [2, 9], [2, 9, 47], [2, 9, 47, 5], [2, 9, 47, 5, 61], [2, 9, 47, 5, 61, 62], [2, 9, 47, 5, 61, 62, 35], [2, 9, 47, 5, 61, 62, 35, 196], [2, 9, 47, 5, 61, 62, 35, 196, 197], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5, 36], [2, 9, 47, 5, 61, 62, 35, 196, 197, 198, 36, 34, 49, 2, 199, 5, 36, 200], [10, 3], [10, 3, 28], [10, 3, 28, 21], [10, 3, 28, 21, 12], [10, 3, 28, 21, 12, 22], [10, 3, 28, 21, 12, 22, 3], [10, 3, 28, 21, 12, 22, 3, 23], [10, 3, 28, 21, 12, 22, 3, 23, 62], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201, 202], [10, 3, 28, 21, 12, 22, 3, 23, 62, 5, 201, 202, 203], [48, 112], [3, 23], [3, 23, 80], [3, 23, 80, 10], [3, 23, 80, 10, 3], [3, 23, 80, 10, 3, 37], [3, 23, 80, 10, 3, 37, 1], [3, 23, 80, 10, 3, 37, 1, 13], [3, 23, 80, 10, 3, 37, 1, 13, 14], [3, 23, 80, 10, 3, 37, 1, 13, 14, 1], [3, 23, 80, 10, 3, 37, 1, 13, 14, 1, 113], [112, 2], [112, 2, 10], [112, 2, 10, 37], [112, 2, 10, 37, 1], [112, 2, 10, 37, 1, 13], [112, 2, 10, 37, 1, 13, 114], [22, 3], [22, 3, 37], [22, 3, 37, 24], [22, 3, 37, 24, 14], [22, 3, 37, 24, 14, 1], [22, 3, 37, 24, 14, 1, 113], [22, 3, 37, 24, 14, 1, 113, 9], [22, 3, 37, 24, 14, 1, 113, 9, 3], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1, 50], [22, 3, 37, 24, 14, 1, 113, 9, 3, 19, 38, 4, 79, 16, 1, 50, 204], [48, 49], [48, 49, 2], [48, 49, 2, 26], [48, 49, 2, 26, 1], [48, 49, 2, 26, 1, 25], [48, 49, 2, 26, 1, 25, 2], [48, 49, 2, 26, 1, 25, 2, 9], [48, 49, 2, 26, 1, 25, 2, 9, 19], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14, 39], [48, 49, 2, 26, 1, 25, 2, 9, 19, 38, 4, 79, 16, 1, 50, 205, 14, 39, 81], [30, 28], [30, 28, 3], [30, 28, 3, 8], [30, 28, 3, 8, 4], [30, 28, 3, 8, 4, 115], [30, 28, 3, 8, 4, 115, 1], [30, 28, 3, 8, 4, 115, 1, 82], [2, 83], [2, 83, 8], [2, 83, 8, 4], [2, 83, 8, 4, 115], [2, 83, 8, 4, 115, 1], [2, 83, 8, 4, 115, 1, 82], [2, 83, 8, 4, 115, 1, 82, 27], [2, 83, 8, 4, 115, 1, 82, 27, 9], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1, 82], [2, 83, 8, 4, 115, 1, 82, 27, 9, 206, 2, 116, 1, 207, 2, 8, 4, 208, 209, 1, 82, 210], [9, 27], [9, 27, 28], [9, 27, 28, 75], [9, 27, 28, 75, 99], [9, 27, 28, 75, 99, 14], [9, 27, 28, 75, 99, 14, 1], [9, 27, 28, 75, 99, 14, 1, 13], [30, 10], [30, 10, 27], [30, 10, 27, 63], [30, 10, 27, 63, 2], [2, 10], [2, 10, 61], [2, 10, 61, 64], [2, 10, 61, 64, 65], [2, 10, 61, 64, 65, 84], [2, 10, 61, 64, 65, 84, 33], [2, 10, 61, 64, 65, 84, 33, 117], [2, 10, 61, 64, 65, 84, 33, 117, 60], [25, 118], [25, 118, 119], [25, 118, 119, 211], [30, 28], [30, 28, 27], [30, 28, 27, 8], [30, 28, 27, 8, 4], [30, 28, 27, 8, 4, 26], [30, 28, 27, 8, 4, 26, 35], [30, 28, 27, 8, 4, 26, 35, 69], [30, 28, 27, 8, 4, 26, 35, 69, 39], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213, 66], [30, 28, 27, 8, 4, 26, 35, 69, 39, 212, 213, 66, 40], [2, 8], [2, 8, 4], [2, 8, 4, 26], [2, 8, 4, 26, 16], [2, 8, 4, 26, 16, 39], [2, 8, 4, 26, 16, 39, 44], [2, 8, 4, 26, 16, 39, 44, 69], [2, 8, 4, 26, 16, 39, 44, 69, 18], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100, 33], [2, 8, 4, 26, 16, 39, 44, 69, 18, 35, 40, 76, 7, 1, 120, 15, 35, 40, 77, 100, 33, 14], [10, 27], [10, 27, 24], [10, 27, 24, 1], [10, 27, 24, 1, 121], [10, 27, 24, 1, 121, 214], [10, 27, 24, 1, 121, 214, 6], [10, 27, 24, 1, 121, 214, 6, 31], [10, 27, 24, 1, 121, 214, 6, 31, 55], [10, 27, 24, 1, 121, 214, 6, 31, 55, 16], [10, 27, 24, 1, 121, 214, 6, 31, 55, 16, 65], [10, 27, 24, 1, 121, 214, 6, 31, 55, 16, 65, 49], [215, 103], [215, 103, 1], [215, 103, 1, 13], [215, 103, 1, 13, 94], [215, 103, 1, 13, 94, 5], [215, 103, 1, 13, 94, 5, 44], [215, 103, 1, 13, 94, 5, 44, 29], [215, 103, 1, 13, 94, 5, 44, 29, 95], [11, 7], [11, 7, 1], [11, 7, 1, 85], [11, 7, 1, 85, 6], [11, 7, 1, 85, 6, 44], [11, 7, 1, 85, 6, 44, 29], [11, 7, 1, 85, 6, 44, 29, 122], [11, 7, 1, 85, 6, 44, 29, 122, 22], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66, 86], [11, 7, 1, 85, 6, 44, 29, 122, 22, 3, 24, 18, 86, 87, 216, 28, 3, 8, 4, 24, 123, 18, 217, 51, 66, 86, 51], [86, 51], [86, 51, 1], [86, 51, 1, 85], [86, 51, 1, 85, 88], [86, 51, 1, 85, 88, 7], [86, 51, 1, 85, 88, 7, 218], [86, 51, 1, 85, 88, 7, 218, 124], [86, 51, 1, 85, 88, 7, 218, 124, 62], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45, 4], [86, 51, 1, 85, 88, 7, 218, 124, 62, 1, 125, 2, 26, 1, 25, 32, 219, 2, 10, 37, 114, 2, 83, 8, 4, 220, 15, 5, 45, 4, 221], [11, 22], [11, 22, 3], [11, 22, 3, 83], [11, 22, 3, 83, 222], [11, 22, 3, 83, 222, 1], [11, 22, 3, 83, 222, 1, 12], [11, 22, 3, 83, 222, 1, 12, 89], [11, 22, 3, 83, 222, 1, 12, 89, 223], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1, 126], [11, 22, 3, 83, 222, 1, 12, 89, 223, 1, 25, 11, 7, 1, 126, 224], [2, 47], [2, 47, 5], [2, 47, 5, 54], [2, 47, 5, 54, 124], [2, 47, 5, 54, 124, 126], [2, 47, 5, 54, 124, 126, 88], [2, 47, 5, 54, 124, 126, 88, 62], [2, 47, 5, 54, 124, 126, 88, 62, 1], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225, 1], [2, 47, 5, 54, 124, 126, 88, 62, 1, 125, 2, 8, 225, 1, 25], [3, 23], [3, 23, 127], [3, 23, 127, 128], [3, 23, 127, 128, 129], [3, 23, 127, 128, 129, 20], [3, 23, 127, 128, 129, 20, 3], [3, 23, 127, 128, 129, 20, 3, 23], [3, 23, 127, 128, 129, 20, 3, 23, 46], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3, 28], [2, 8], [2, 8, 4], [2, 8, 4, 63], [2, 8, 4, 63, 64], [2, 8, 4, 63, 64, 59], [2, 8, 4, 63, 64, 59, 131], [2, 8, 4, 63, 64, 59, 131, 5], [2, 8, 4, 63, 64, 59, 131, 5, 61], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 117], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 117, 60], [226, 118], [226, 118, 132], [90, 227], [90, 227, 10], [90, 227, 10, 3], [90, 227, 10, 3, 228], [90, 227, 10, 3, 228, 1], [90, 227, 10, 3, 228, 1, 36], [90, 227, 10, 3, 228, 1, 36, 133], [90, 227, 10, 3, 228, 1, 36, 133, 18], [90, 227, 10, 3, 228, 1, 36, 133, 18, 1], [90, 227, 10, 3, 228, 1, 36, 133, 18, 1, 40], [21, 229], [21, 229, 7], [21, 229, 7, 230], [21, 229, 7, 230, 32], [21, 229, 7, 230, 32, 134], [21, 229, 7, 230, 32, 134, 231], [21, 229, 7, 230, 32, 134, 231, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1, 29], [21, 229, 7, 230, 32, 134, 231, 2, 10, 57, 1, 133, 90, 39, 29, 7, 232, 122, 2, 8, 233, 29, 18, 91, 87, 2, 9, 19, 38, 4, 57, 16, 1, 50, 36, 17, 14, 1, 88, 6, 91, 87, 4, 234, 51, 135, 89, 91, 51, 2, 9, 8, 4, 235, 1, 29, 123], [135, 49], [135, 49, 1], [135, 49, 1, 12], [135, 49, 1, 12, 7], [135, 49, 1, 12, 7, 236], [135, 49, 1, 12, 7, 236, 20], [135, 49, 1, 12, 7, 236, 20, 2], [135, 49, 1, 12, 7, 236, 20, 2, 8], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90, 238], [135, 49, 1, 12, 7, 236, 20, 2, 8, 36, 64, 31, 55, 66, 54, 237, 6, 31, 70, 2, 9, 19, 38, 4, 57, 1, 36, 17, 90, 238, 239], [240, 241], [240, 241, 85], [240, 241, 85, 7], [240, 241, 85, 7, 46], [240, 241, 85, 7, 46, 136], [242, 6], [242, 6, 1], [242, 6, 1, 243], [242, 6, 1, 243, 12], [242, 6, 1, 243, 12, 42], [30, 10], [30, 10, 3], [30, 10, 3, 244], [30, 10, 3, 244, 245], [30, 10, 3, 244, 245, 14], [30, 10, 3, 244, 245, 14, 75], [30, 10, 3, 244, 245, 14, 75, 6], [30, 10, 3, 244, 245, 14, 75, 6, 5], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89, 1], [30, 10, 3, 244, 245, 14, 75, 6, 5, 67, 89, 1, 34], [2, 9], [2, 9, 8], [2, 9, 8, 4], [2, 9, 8, 4, 246], [2, 9, 8, 4, 246, 5], [2, 9, 8, 4, 246, 5, 58], [2, 9, 8, 4, 246, 5, 58, 137], [2, 9, 8, 4, 246, 5, 58, 137, 136], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67, 139], [2, 9, 8, 4, 246, 5, 58, 137, 136, 14, 39, 81, 20, 35, 247, 9, 63, 2, 15, 5, 138, 18, 138, 67, 139, 34], [22, 3], [22, 3, 37], [22, 3, 37, 1], [22, 3, 37, 1, 13], [22, 3, 37, 1, 13, 80], [22, 3, 37, 1, 13, 80, 10], [22, 3, 37, 1, 13, 80, 10, 3], [22, 3, 37, 1, 13, 80, 10, 3, 248], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50, 140], [22, 3, 37, 1, 13, 80, 10, 3, 248, 249, 50, 140, 250], [48, 141], [48, 141, 251], [48, 141, 251, 50], [48, 141, 251, 50, 140], [48, 141, 251, 50, 140, 67], [48, 141, 251, 50, 140, 67, 14], [48, 141, 251, 50, 140, 67, 14, 1], [48, 141, 251, 50, 140, 67, 14, 1, 67], [48, 141, 251, 50, 140, 67, 14, 1, 67, 139], [48, 141, 251, 50, 140, 67, 14, 1, 67, 139, 58], [48, 141, 251, 50, 140, 67, 14, 1, 67, 139, 58, 137], [3, 23], [3, 23, 127], [3, 23, 127, 128], [3, 23, 127, 128, 129], [3, 23, 127, 128, 129, 20], [3, 23, 127, 128, 129, 20, 3], [3, 23, 127, 128, 129, 20, 3, 23], [3, 23, 127, 128, 129, 20, 3, 23, 46], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3], [3, 23, 127, 128, 129, 20, 3, 23, 46, 38, 4, 26, 1, 25, 18, 1, 40, 11, 130, 3, 28], [2, 8], [2, 8, 4], [2, 8, 4, 63], [2, 8, 4, 63, 64], [2, 8, 4, 63, 64, 59], [2, 8, 4, 63, 64, 59, 131], [2, 8, 4, 63, 64, 59, 131, 5], [2, 8, 4, 63, 64, 59, 131, 5, 61], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 252], [2, 8, 4, 63, 64, 59, 131, 5, 61, 65, 84, 33, 252, 60], [142, 20], [142, 20, 41], [142, 20, 41, 52], [142, 20, 41, 52, 119], [142, 20, 41, 52, 119, 132], [11, 7], [11, 7, 1], [11, 7, 1, 253], [11, 7, 1, 253, 4], [11, 7, 1, 253, 4, 47], [11, 7, 1, 253, 4, 47, 1], [11, 7, 1, 253, 4, 47, 1, 142], [254, 56], [254, 56, 110], [254, 56, 110, 255], [2, 8], [2, 8, 4], [2, 8, 4, 24], [2, 8, 4, 24, 1], [2, 8, 4, 24, 1, 121], [2, 8, 4, 24, 1, 121, 42], [2, 8, 4, 24, 1, 121, 42, 6], [2, 8, 4, 24, 1, 121, 42, 6, 31], [2, 8, 4, 24, 1, 121, 42, 6, 31, 55], [2, 8], [2, 8, 4], [2, 8, 4, 256], [2, 8, 4, 256, 16], [2, 8, 4, 256, 16, 1], [2, 8, 4, 256, 16, 1, 12], [2, 8, 4, 256, 16, 1, 12, 257], [3, 23], [3, 23, 258], [3, 23, 258, 80], [3, 23, 258, 80, 111], [3, 23, 258, 80, 111, 10], [3, 23, 258, 80, 111, 10, 3], [3, 23, 258, 80, 111, 10, 3, 24], [3, 23, 258, 80, 111, 10, 3, 24, 25], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1, 143], [3, 23, 258, 80, 111, 10, 3, 24, 25, 6, 1, 143, 73], [2, 9], [2, 9, 47], [2, 9, 47, 5], [2, 9, 47, 5, 120], [2, 9, 47, 5, 120, 4], [2, 9, 47, 5, 120, 4, 24], [2, 9, 47, 5, 120, 4, 24, 42], [2, 9, 47, 5, 120, 4, 24, 42, 6], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1, 259], [2, 9, 47, 5, 120, 4, 24, 42, 6, 143, 73, 14, 39, 81, 49, 2, 24, 15, 1, 259, 45], [3, 8], [3, 8, 134], [3, 8, 134, 92], [3, 8, 134, 92, 41], [3, 8, 134, 92, 41, 52], [3, 8, 134, 92, 41, 52, 7], [3, 8, 134, 92, 41, 52, 7, 5], [3, 8, 134, 92, 41, 52, 7, 5, 78], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145, 41], [3, 8, 134, 92, 41, 52, 7, 5, 78, 6, 21, 13, 11, 144, 145, 41, 52], [21, 7], [21, 7, 4], [21, 7, 4, 260], [21, 7, 4, 260, 92], [21, 7, 4, 260, 92, 41], [21, 7, 4, 260, 92, 41, 52], [21, 7, 4, 260, 92, 41, 52, 261], [21, 7, 4, 260, 92, 41, 52, 261, 46], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145, 41], [21, 7, 4, 260, 92, 41, 52, 261, 46, 262, 41, 146, 32, 27, 263, 146, 2, 264, 265, 66, 15, 92, 266, 107, 267, 268, 32, 22, 2, 56, 269, 4, 37, 21, 12, 141, 15, 270, 3, 23, 271, 2, 9, 19, 272, 76, 7, 11, 144, 145, 41, 52], [273, 274], [273, 274, 17], [275, 276], [275, 276, 17], [17, 116], [17, 116, 277], [17, 116, 277, 278], [279, 18], [279, 18, 280], [279, 18, 280, 281], [279, 18, 280, 281, 282]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = max([len(x) for x in input_sequences])\n",
        "max_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXFZvONqg6II",
        "outputId": "15a48055-32ab-40b9-9baf-2893638679a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding='pre')"
      ],
      "metadata": {
        "id": "BSUYf85gjNJQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_input_sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUB4WjpjjY-G",
        "outputId": "762ca5d8-74f4-44e6-8b3e-8283b9b310ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0, ...,   0,  93,   1],\n",
              "       [  0,   0,   0, ...,  93,   1,  13],\n",
              "       [  0,   0,   0, ...,   0,  11,   7],\n",
              "       ...,\n",
              "       [  0,   0,   0, ..., 279,  18, 280],\n",
              "       [  0,   0,   0, ...,  18, 280, 281],\n",
              "       [  0,   0,   0, ..., 280, 281, 282]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = padded_input_sequences[:,:-1]"
      ],
      "metadata": {
        "id": "uJV1jWO6ja5-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = padded_input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "G9wZBfDnji4S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVNsU0HDjnNQ",
        "outputId": "dc55e96c-5fec-4182-c46f-7d1beafccba0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863, 56)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EpuozUcjo1s",
        "outputId": "990630dd-2fdb-40a1-e0ad-6935b0b705f9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len_words = len(tokenizer.word_counts)+1"
      ],
      "metadata": {
        "id": "_JWAIAS26pT7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vppuV9sd6-0c",
        "outputId": "02c72475-28d0-46df-de28-d146e8ea4d64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "283"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(y, num_classes=len_words)"
      ],
      "metadata": {
        "id": "A6O6d7Ihjt_s"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te56Ze0s7B2L",
        "outputId": "48ed8eef-aa7a-4fa2-dba3-3c8bf581e9df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(863, 283)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "LDFkwFrS7LuQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(len_words, 100, input_length=56))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(len_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "4OU1y-M67OQv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZJt6gfHwLMWm"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=100, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7yhP1j2Lsh4",
        "outputId": "c7ac0431-810f-491f-8f30-0b228f1e311f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9563 - loss: 0.1638 - val_accuracy: 0.9480 - val_loss: 0.2016\n",
            "Epoch 2/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 137ms/step - accuracy: 0.9458 - loss: 0.1813 - val_accuracy: 0.9480 - val_loss: 0.2249\n",
            "Epoch 3/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9520 - loss: 0.1685 - val_accuracy: 0.9364 - val_loss: 0.2407\n",
            "Epoch 4/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9574 - loss: 0.1487 - val_accuracy: 0.9364 - val_loss: 0.2568\n",
            "Epoch 5/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - accuracy: 0.9382 - loss: 0.1747 - val_accuracy: 0.9422 - val_loss: 0.2636\n",
            "Epoch 6/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 133ms/step - accuracy: 0.9538 - loss: 0.1458 - val_accuracy: 0.9249 - val_loss: 0.2715\n",
            "Epoch 7/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9406 - loss: 0.1630 - val_accuracy: 0.9249 - val_loss: 0.2837\n",
            "Epoch 8/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9450 - loss: 0.1547 - val_accuracy: 0.9364 - val_loss: 0.2873\n",
            "Epoch 9/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9494 - loss: 0.1452 - val_accuracy: 0.9191 - val_loss: 0.2975\n",
            "Epoch 10/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9656 - loss: 0.1257 - val_accuracy: 0.9249 - val_loss: 0.3041\n",
            "Epoch 11/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9425 - loss: 0.1621 - val_accuracy: 0.9306 - val_loss: 0.3088\n",
            "Epoch 12/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9625 - loss: 0.1225 - val_accuracy: 0.9249 - val_loss: 0.3162\n",
            "Epoch 13/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.9279 - loss: 0.1748 - val_accuracy: 0.9249 - val_loss: 0.3199\n",
            "Epoch 14/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.9341 - loss: 0.1319 - val_accuracy: 0.9306 - val_loss: 0.3242\n",
            "Epoch 15/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9464 - loss: 0.1402 - val_accuracy: 0.9133 - val_loss: 0.3321\n",
            "Epoch 16/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 151ms/step - accuracy: 0.9494 - loss: 0.1427 - val_accuracy: 0.9017 - val_loss: 0.3430\n",
            "Epoch 17/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9476 - loss: 0.1398 - val_accuracy: 0.9191 - val_loss: 0.3405\n",
            "Epoch 18/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9655 - loss: 0.1170 - val_accuracy: 0.9249 - val_loss: 0.3448\n",
            "Epoch 19/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 131ms/step - accuracy: 0.9462 - loss: 0.1396 - val_accuracy: 0.9017 - val_loss: 0.3516\n",
            "Epoch 20/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9524 - loss: 0.1278 - val_accuracy: 0.9306 - val_loss: 0.3542\n",
            "Epoch 21/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9524 - loss: 0.1245 - val_accuracy: 0.9249 - val_loss: 0.3560\n",
            "Epoch 22/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9624 - loss: 0.1082 - val_accuracy: 0.9017 - val_loss: 0.3665\n",
            "Epoch 23/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9420 - loss: 0.1385 - val_accuracy: 0.9191 - val_loss: 0.3687\n",
            "Epoch 24/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.9584 - loss: 0.1228 - val_accuracy: 0.9017 - val_loss: 0.3758\n",
            "Epoch 25/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - accuracy: 0.9649 - loss: 0.1116 - val_accuracy: 0.9017 - val_loss: 0.3758\n",
            "Epoch 26/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 180ms/step - accuracy: 0.9455 - loss: 0.1120 - val_accuracy: 0.8902 - val_loss: 0.3808\n",
            "Epoch 27/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9536 - loss: 0.1078 - val_accuracy: 0.9191 - val_loss: 0.3837\n",
            "Epoch 28/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9435 - loss: 0.1239 - val_accuracy: 0.9017 - val_loss: 0.3873\n",
            "Epoch 29/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9460 - loss: 0.1160 - val_accuracy: 0.9075 - val_loss: 0.3901\n",
            "Epoch 30/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 160ms/step - accuracy: 0.9486 - loss: 0.1211 - val_accuracy: 0.9191 - val_loss: 0.3932\n",
            "Epoch 31/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9383 - loss: 0.1300 - val_accuracy: 0.9017 - val_loss: 0.3990\n",
            "Epoch 32/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.9451 - loss: 0.1421 - val_accuracy: 0.8960 - val_loss: 0.4012\n",
            "Epoch 33/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step - accuracy: 0.9403 - loss: 0.1250 - val_accuracy: 0.9133 - val_loss: 0.4049\n",
            "Epoch 34/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9615 - loss: 0.0940 - val_accuracy: 0.8902 - val_loss: 0.4092\n",
            "Epoch 35/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - accuracy: 0.9565 - loss: 0.1010 - val_accuracy: 0.9017 - val_loss: 0.4099\n",
            "Epoch 36/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 167ms/step - accuracy: 0.9554 - loss: 0.1103 - val_accuracy: 0.9133 - val_loss: 0.4150\n",
            "Epoch 37/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 135ms/step - accuracy: 0.9485 - loss: 0.1165 - val_accuracy: 0.9075 - val_loss: 0.4194\n",
            "Epoch 38/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9457 - loss: 0.1132 - val_accuracy: 0.9017 - val_loss: 0.4211\n",
            "Epoch 39/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 142ms/step - accuracy: 0.9461 - loss: 0.1126 - val_accuracy: 0.8960 - val_loss: 0.4276\n",
            "Epoch 40/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 140ms/step - accuracy: 0.9541 - loss: 0.1167 - val_accuracy: 0.9017 - val_loss: 0.4271\n",
            "Epoch 41/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9634 - loss: 0.0979 - val_accuracy: 0.9133 - val_loss: 0.4299\n",
            "Epoch 42/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9389 - loss: 0.1134 - val_accuracy: 0.8844 - val_loss: 0.4422\n",
            "Epoch 43/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - accuracy: 0.9519 - loss: 0.1072 - val_accuracy: 0.9017 - val_loss: 0.4399\n",
            "Epoch 44/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9468 - loss: 0.1184 - val_accuracy: 0.9133 - val_loss: 0.4385\n",
            "Epoch 45/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.9500 - loss: 0.1155 - val_accuracy: 0.8902 - val_loss: 0.4436\n",
            "Epoch 46/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.9515 - loss: 0.0981 - val_accuracy: 0.8844 - val_loss: 0.4494\n",
            "Epoch 47/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9642 - loss: 0.0970 - val_accuracy: 0.9017 - val_loss: 0.4475\n",
            "Epoch 48/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9522 - loss: 0.1104 - val_accuracy: 0.9075 - val_loss: 0.4499\n",
            "Epoch 49/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9526 - loss: 0.1159 - val_accuracy: 0.8844 - val_loss: 0.4602\n",
            "Epoch 50/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 156ms/step - accuracy: 0.9457 - loss: 0.1177 - val_accuracy: 0.8902 - val_loss: 0.4603\n",
            "Epoch 51/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9580 - loss: 0.0967 - val_accuracy: 0.9017 - val_loss: 0.4641\n",
            "Epoch 52/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 132ms/step - accuracy: 0.9503 - loss: 0.1079 - val_accuracy: 0.9075 - val_loss: 0.4670\n",
            "Epoch 53/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - accuracy: 0.9513 - loss: 0.0923 - val_accuracy: 0.9017 - val_loss: 0.4712\n",
            "Epoch 54/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9430 - loss: 0.1077 - val_accuracy: 0.8960 - val_loss: 0.4690\n",
            "Epoch 55/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.9466 - loss: 0.1164 - val_accuracy: 0.8960 - val_loss: 0.4760\n",
            "Epoch 56/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9349 - loss: 0.1247 - val_accuracy: 0.8960 - val_loss: 0.4781\n",
            "Epoch 57/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.9545 - loss: 0.0968 - val_accuracy: 0.9017 - val_loss: 0.4791\n",
            "Epoch 58/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9473 - loss: 0.1117 - val_accuracy: 0.8902 - val_loss: 0.4876\n",
            "Epoch 59/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9600 - loss: 0.0974 - val_accuracy: 0.8902 - val_loss: 0.4840\n",
            "Epoch 60/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9381 - loss: 0.1131 - val_accuracy: 0.8902 - val_loss: 0.4953\n",
            "Epoch 61/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step - accuracy: 0.9520 - loss: 0.1086 - val_accuracy: 0.9075 - val_loss: 0.4889\n",
            "Epoch 62/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9456 - loss: 0.1130 - val_accuracy: 0.8844 - val_loss: 0.4939\n",
            "Epoch 63/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9477 - loss: 0.1107 - val_accuracy: 0.8960 - val_loss: 0.4979\n",
            "Epoch 64/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9655 - loss: 0.0941 - val_accuracy: 0.8786 - val_loss: 0.5040\n",
            "Epoch 65/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 155ms/step - accuracy: 0.9409 - loss: 0.1150 - val_accuracy: 0.8844 - val_loss: 0.5081\n",
            "Epoch 66/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9462 - loss: 0.1075 - val_accuracy: 0.8844 - val_loss: 0.5076\n",
            "Epoch 67/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.9510 - loss: 0.0890 - val_accuracy: 0.8902 - val_loss: 0.5081\n",
            "Epoch 68/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.9529 - loss: 0.0944 - val_accuracy: 0.8902 - val_loss: 0.5113\n",
            "Epoch 69/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9550 - loss: 0.0957 - val_accuracy: 0.8902 - val_loss: 0.5109\n",
            "Epoch 70/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.9487 - loss: 0.1025 - val_accuracy: 0.8786 - val_loss: 0.5193\n",
            "Epoch 71/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.9524 - loss: 0.0984 - val_accuracy: 0.8844 - val_loss: 0.5177\n",
            "Epoch 72/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9511 - loss: 0.0988 - val_accuracy: 0.8786 - val_loss: 0.5275\n",
            "Epoch 73/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9483 - loss: 0.0986 - val_accuracy: 0.8786 - val_loss: 0.5291\n",
            "Epoch 74/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.9618 - loss: 0.0884 - val_accuracy: 0.8786 - val_loss: 0.5286\n",
            "Epoch 75/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 160ms/step - accuracy: 0.9558 - loss: 0.0978 - val_accuracy: 0.8960 - val_loss: 0.5282\n",
            "Epoch 76/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9420 - loss: 0.1221 - val_accuracy: 0.8902 - val_loss: 0.5313\n",
            "Epoch 77/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9644 - loss: 0.0841 - val_accuracy: 0.8902 - val_loss: 0.5333\n",
            "Epoch 78/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - accuracy: 0.9352 - loss: 0.1199 - val_accuracy: 0.8786 - val_loss: 0.5423\n",
            "Epoch 79/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9493 - loss: 0.1062 - val_accuracy: 0.8844 - val_loss: 0.5413\n",
            "Epoch 80/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - accuracy: 0.9515 - loss: 0.1021 - val_accuracy: 0.8844 - val_loss: 0.5453\n",
            "Epoch 81/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 157ms/step - accuracy: 0.9349 - loss: 0.1125 - val_accuracy: 0.8786 - val_loss: 0.5436\n",
            "Epoch 82/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9531 - loss: 0.0950 - val_accuracy: 0.8671 - val_loss: 0.5578\n",
            "Epoch 83/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - accuracy: 0.9413 - loss: 0.1005 - val_accuracy: 0.8844 - val_loss: 0.5539\n",
            "Epoch 84/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.9506 - loss: 0.0902 - val_accuracy: 0.8902 - val_loss: 0.5552\n",
            "Epoch 85/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.9550 - loss: 0.1035 - val_accuracy: 0.8902 - val_loss: 0.5591\n",
            "Epoch 86/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.9429 - loss: 0.1031 - val_accuracy: 0.8786 - val_loss: 0.5619\n",
            "Epoch 87/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - accuracy: 0.9527 - loss: 0.0939 - val_accuracy: 0.8786 - val_loss: 0.5631\n",
            "Epoch 88/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.9514 - loss: 0.1054 - val_accuracy: 0.8786 - val_loss: 0.5675\n",
            "Epoch 89/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.9518 - loss: 0.0852 - val_accuracy: 0.8902 - val_loss: 0.5695\n",
            "Epoch 90/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.9484 - loss: 0.0973 - val_accuracy: 0.8844 - val_loss: 0.5682\n",
            "Epoch 91/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.9446 - loss: 0.1003 - val_accuracy: 0.8728 - val_loss: 0.5782\n",
            "Epoch 92/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - accuracy: 0.9339 - loss: 0.1094 - val_accuracy: 0.8844 - val_loss: 0.5767\n",
            "Epoch 93/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.9534 - loss: 0.0988 - val_accuracy: 0.8786 - val_loss: 0.5790\n",
            "Epoch 94/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.9473 - loss: 0.1032 - val_accuracy: 0.8786 - val_loss: 0.5818\n",
            "Epoch 95/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.9473 - loss: 0.1063 - val_accuracy: 0.8786 - val_loss: 0.5859\n",
            "Epoch 96/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.9519 - loss: 0.0947 - val_accuracy: 0.8844 - val_loss: 0.5882\n",
            "Epoch 97/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.9412 - loss: 0.1098 - val_accuracy: 0.8902 - val_loss: 0.5867\n",
            "Epoch 98/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.9444 - loss: 0.1056 - val_accuracy: 0.8960 - val_loss: 0.5882\n",
            "Epoch 99/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.9420 - loss: 0.1035 - val_accuracy: 0.8671 - val_loss: 0.5958\n",
            "Epoch 100/100\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.9496 - loss: 0.0898 - val_accuracy: 0.8671 - val_loss: 0.5991\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e84b020d3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "G0y1YBW_LkJ5",
        "outputId": "c49f26f4-767d-4b2e-9ddf-1e2d616ff34f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m28,300\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m150\u001b[0m)        │       \u001b[38;5;34m150,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m180,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m283\u001b[0m)            │        \u001b[38;5;34m42,733\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">28,300</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">180,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">283</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">42,733</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,206,701\u001b[0m (4.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,206,701</span> (4.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m402,233\u001b[0m (1.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,233</span> (1.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m804,468\u001b[0m (3.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">804,468</span> (3.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "\n",
        "text = \"what is the validity\"\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
        "\n",
        "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
        "\n",
        "  pos = np.argmax(model.predict(padded_token_text))\n",
        "\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == pos:\n",
        "      text = text + \" \" + word\n",
        "      print(text)\n",
        "      time.sleep(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5efIt_4FO-PD",
        "outputId": "c3f97666-4969-4aa7-f866-5bd43037a1d2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "what is the validity of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "what is the validity of monthly\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "what is the validity of monthly subscription\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "what is the validity of monthly subscription suppose\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "what is the validity of monthly subscription suppose if\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "what is the validity of monthly subscription suppose if i\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "what is the validity of monthly subscription suppose if i pay\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "what is the validity of monthly subscription suppose if i pay on\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "what is the validity of monthly subscription suppose if i pay on 15th\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "what is the validity of monthly subscription suppose if i pay on 15th jan\n"
          ]
        }
      ]
    }
  ]
}